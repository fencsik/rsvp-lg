---
title: "Clean Data"
author: "David Fencsik"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE)
library(tidyverse)

this_file = "01-CleanData"
source_file = "00-GatherData"
```

# Purpose

Clean the task and survey data files and the survey data, correct some known problems, do some sanity checking, and then prepare them for later analysis

# Load Data

```{r loaddata}
load(sprintf("%s.RData", source_file))
```

# Clean Data

1. Lowercase and rename survey data columns

```{r cleandata1}
names(surveyData) = tolower(names(surveyData))
names(surveyData)[names(surveyData) == "id"] = "sub"
```

1. Remove data lines that have NA values from a crash or empty survey responses

```{r cleandata2}
rsvpData = rsvpData[!is.na(rsvpData$sub), ]
surveyData = surveyData[!is.na(surveyData$sub), ]
```

3. Remove test runs (Subjects w/ IDs >= 900)

```{r cleandata3}
rsvpData = rsvpData[rsvpData$sub < 900, ]
surveyData = surveyData[surveyData$sub < 900, ]
```

4. Correct subject ID typos

```{r cleandata4}
print("317 -> 137")
rsvpData$sub[with(rsvpData, sub == 317 & experimenter == "SN")] = 137
print("514 -> 154")
rsvpData$sub[with(rsvpData, sub == 514 & experimenter == "AGM")] = 154
surveyData$sub[with(surveyData, sub == 514 & startdate == "10/24/23 17:10")] = 154
print("One of the subjects labeled 157 -> 156")
rsvpData$sub[with(rsvpData, sub == 157 & experimenter == "ng")] = 156
surveyData$sub[with(surveyData, sub == 157 & startdate == "10/26/23 16:16")] = 156
```

5. Remove minors

```{r cleandata5}
nonminors = with(surveyData, is.na(age) | age >= 18)
if (any(!nonminors)) {
  print("Minors detected in data and will be removed:")
  print(sort(surveyData[!nonminors, "sub"]))
  surveyData = surveyData[nonminors, ]
  # these subjects will be removed automatically from the RSVP data set when we merge the two
} else {
  print("No minors detected in data")
}
```

6. Recode gender to labeled factors

```{r, cleandata6}
# recode gender (0->male, 1->female, 2->transmale, 3->transfemale, 4->nonbinary, 5->agender, 6->other)
surveyData$gender = factor(surveyData$gender, levels=as.character(0:6),
                           labels=c("male", "female", "transmale", "transfemale",
                                    "nonbinary", "agender", "other"))
```


7. Create a common set of subjects across the two data sets. Note that subject 124 was run through the RSVP task, but the RA forgot to run them through the survey.

```{r, cleandata7}
subRSVP = sort(unique(rsvpData$sub))
subSurvey = sort(unique(surveyData$sub))
subCommon = intersect(subRSVP, subSurvey)
sprintf("Subjects in RSVP data set but not Survey data set: %s",
        paste(setdiff(subRSVP, subSurvey), collapse=", "))
sprintf("Subjects in Survey data set but not RSVP data set: %s",
        paste(setdiff(subSurvey, subRSVP), collapse=", "))
rsvpData = rsvpData[rsvpData$sub %in% subCommon, ]
surveyData = surveyData[surveyData$sub %in% subCommon, ]
```

8. Remove duplicate survey data (subject 320)

```{r, removedups}
surveyData = surveyData |>
  filter(!(sub == 320 & is.na(age)))
```

9. Get a list of subject IDs sorted by start date/time

```{r, sortedsubjectids}
orderedSurvey = surveyData |>
  mutate(starttime = strptime(startdate, "%m/%d/%y %H:%M")) |>
  arrange(starttime) |>
  select(sub)
orderedSub = orderedSurvey$sub
print("test for duplicate subject ids")
if (length(orderedSub) != length(unique(orderedSub))) {
  print("there are duplicated subjects")
  print(orderedSub[duplicated(orderedSub)])
} else {
  print("no duplicates detected")
}

```

# Sanity Checks

Check for min and max counts on numbers of trials in each condition. Some subjects were run with code that had 20 trials per cell, but we decided that was taking too long so we reduced it to 15 trials per cell. Some subjects were then run under the old version of the code with 20, but most were run with 15. Two subjects were cut off 5 trials early due to an RA's misunderstanding, so they are missing trials in various conditions.

Here are two tables that count the number of trials in each cell, sort by that number, then show the highest and lowest ones.

```{r, trialcount}
x = rsvpData |>
  filter(blocktyp == "Experiment" & trial_type == "exp") |>
  group_by(sub, t1_level, t2_level, t2_lag) |>
  summarize(n=n()) |>
  ungroup() |>
  group_by(sub) |>
  summarize(max=max(n),
            min=min(n)) |>
  ungroup()
x |> arrange(min) |> select(sub, min) |> head(20)
x |> arrange(max) |> select(sub, max) |> tail(20)
```

# Anonymize Data

Remove any columns that could be used to identify subjects

```{r anonymize2}
rsvpCols2Keep = c("exp", "ver", "sub", "experimenter", "blocktyp", "sess",
                  "trial", "trial_type", "t1_level", "t2_level", "t2_lag",
                  "global_letters", "local_letters", "t1_pos", "t1", "t1_corr",
                  "t1_resp", "t1_acc", "t2", "t2_corr", "t2_resp", "t2_acc",
                  "t1_rt", "t2_rt")
survCols2Keep = c("sub", "age", "gender",  "gender_6_text",
                  "bsam1", "bsam2", "bsam3", "bsam4", "bsam5", "bsam6",
                  "sias6_1", "sias6_2", "sias6_3", "sias6_4", "sias6_5", "sias6_6",
                  "promisd1", "promisd2", "promisd3", "promisd4", "promisd5",
                  "promisd6", "promisd7", "promisd8", "promisa1", "promisa2",
                  "promisa3", "promisa4", "promisa5", "promisa6", "promisa7",
                  "promisa8", "progress", "finished")
rsvpDataAnon = rsvpData[, rsvpCols2Keep]
surveyDataAnon = surveyData[, survCols2Keep]
```

# Generate Aggregated Data Set

Create a data set that aggregates accuracies and survey totals for each combination of subject and IV levels.

```{r, loaddata2}
# rename data files
dfRSVP = rsvpDataAnon
dfSurvey = surveyDataAnon
```

## Survey Totals

Recode survey questions where needed, then create sums for each survey.

```{r, surveys}
dfSurvey$gender = factor(dfSurvey$gender)

# reverse code BSAM items (1, 2 and 4)
dfSurvey$bsam1 = 5 - dfSurvey$bsam1
dfSurvey$bsam2 = 5 - dfSurvey$bsam2
dfSurvey$bsam4 = 5 - dfSurvey$bsam4

# create sum of survey's scores'
# Brief State Anxiety Measure (BSAM)
dfSurvey = dfSurvey |>
  rowwise() |> mutate(sumbsam=sum(c_across(starts_with("bsam"))))
# Social Interaction Anxiety Scale (SIAS)
dfSurvey = dfSurvey |>
  rowwise() |> mutate(sumsias6=sum(c_across(starts_with("sias6"))))
# Patient-Reported Outcomes Measurement Information System - Depression (PROMIS-D)
dfSurvey = dfSurvey |>
  rowwise() |> mutate(sumpromisd=sum(c_across(starts_with("promisd"))))
# Patient-Reported Outcomes Measurement Information System - Anxiety (PROMIS-A)
dfSurvey = dfSurvey |>
  rowwise() |> mutate(sumpromisa=sum(c_across(starts_with("promisa"))))
length(unique(dfSurvey$sub))
dim(dfSurvey)
```

## Aggregate Accuracies

Remove non-experimental trials and weird responses (acc < 0), then extract overall T1 and T2 accuracy, and T2 accuracy conditional on T1, for each cell.

```{r, rsvp1}
# filter out non-experimental trials and any with weird responses
dfRSVP2 = dfRSVP |>
  filter(blocktyp == "Experiment" & trial_type == "exp") |>
  filter(t1_acc >= 0 & t2_acc >= 0)
# get T1 accuracy and overall T2 hit rate
rsvp1 = dfRSVP2 |>
  group_by(sub, t1_level, t2_level, t2_lag, .drop=FALSE) |>
  summarize(t1acc = mean(t1_acc, na.rm=TRUE),
            t2acc=mean(t2_acc, na.rm=TRUE),
            .groups = "drop_last") |>
  ungroup()

# get T2 hit rate conditional on correct T1 responses
rsvpt2t1 = dfRSVP2 |>
  group_by(sub, t1_level, t2_level, t2_lag, .drop=FALSE) |>
  filter(t1_acc == 1, .preserve=FALSE) |>
  summarize(t2t1acc = mean(t2_acc, na.rm=TRUE),
            .groups = "drop_last") |>
  ungroup()
```

## Check Factor Levels

Sanity check to make sure the overall and conditional data sets have the same factors and levels.

```{r, sanitycheck}
rsvp2 = rsvp1
# check that these columns match
col2fac = c("sub", "t1_level", "t2_level", "t2_lag")
# convert those columns to factors
rsvp2[col2fac] = lapply(rsvp2[col2fac], factor)
rsvpt2t1[col2fac] = lapply(rsvpt2t1[col2fac], factor)
summary(rsvp2)
print(length(levels(rsvp2$sub)))
summary(rsvpt2t1)
print(length(levels(rsvpt2t1$sub)))
# combine the levels in those columns
labels1 = rsvp2 |>
  unite("vars", all_of(col2fac), remove=TRUE, sep="-")
labels2 = rsvpt2t1 |>
  unite("vars", all_of(col2fac), remove=TRUE, sep="-")
# make sure the factor combos match in the two datasets
print(length(labels1$vars))
print(length(labels2$vars))
if (!all(labels1$vars == labels2$vars)) {
  print("mismatch")
  knitr::knit_exit()
} else {
  print("good")
}
```

## Add Conditional Accuracy

Add the conditional T2 accuracy to the first data set.

```{r, rsvp2}
rsvp1$t2t1acc = rsvpt2t1$t2t1acc
```

## Add Survey Data

```{r, addsurvey}
rsvp1$age = -1
rsvp1$gender = ""
rsvp1$bsam = -1
rsvp1$sias6 = -1
rsvp1$promisa = -1
rsvp1$promisd = -1
dfSurvey$gender = as.character(dfSurvey$gender)
for (i in 1:nrow(dfSurvey)) {
  index = rsvp1$sub == dfSurvey$sub[i]
  rsvp1$age[index] = dfSurvey$age[i]
  rsvp1$gender[index] = dfSurvey$gender[i]
  rsvp1$bsam[index] = dfSurvey$sumbsam[i]
  rsvp1$sias6[index] = dfSurvey$sumsias6[i]
  rsvp1$promisa[index] = dfSurvey$sumpromisa[i]
  rsvp1$promisd[index] = dfSurvey$sumpromisd[i]
}
rsvp1$gender = factor(rsvp1$gender)
summary(rsvp1)
rsvpAggregate = rsvp1
```

# Save Data

```{r savedata}
save(rsvpDataAnon, surveyDataAnon, rsvpAggregate, file=sprintf("%s.RData", this_file))
```
